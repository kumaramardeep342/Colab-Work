{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1NHv8MY_TRPl5aUA1Jgy95m6P2ABJp4-k",
      "authorship_tag": "ABX9TyMUrx5uDXh4xKzVKGga11g+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumaramardeep342/Colab-Work/blob/main/Tuning_%2B_Scratch_%2B_Adaptation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "- Dataset - CIFAR10 & FashionMNIST\n",
        "- Pre-Trained Model - ResNet18\n",
        "- Shallow Tunning\n",
        "- Deep Tunning\n",
        "- Training from Scratch\n",
        "- Domain Adoption - how is model performance on different dataset.\n"
      ],
      "metadata": {
        "id": "W75sCZdb67fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import all the necessary libraries"
      ],
      "metadata": {
        "id": "AeFIj1ac7CVJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKE-k-V85K15",
        "outputId": "dd75dd98-fdb0-45a9-996d-217cb8bdce02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.4.2-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.7 torchmetrics-1.4.2\n"
          ]
        }
      ],
      "source": [
        "# data anyalysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#modeling using Pytorch\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10, FashionMNIST\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from tqdm import tqdm\n",
        "!pip install torchmetrics\n",
        "from torchmetrics import Accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the Data Class (CIFAR10 & FashionMNIST)\n"
      ],
      "metadata": {
        "id": "wLROHMluAO_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is where we define the data\n",
        "class DataModule():\n",
        "  #save all the hyper - parameters here\n",
        "    def __init__(self, batch_size,fmnist=False):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.fmnist = fmnist\n",
        "\n",
        "        # We define some augmentations that we would like to apply during training\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.RandomCrop(224, 4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ])\n",
        "\n",
        "        # During validation we need to only normalize and resize\n",
        "        self.val_transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ])\n",
        "\n",
        "        if self.fmnist:\n",
        "          self.train_transform = transforms.Compose([\n",
        "          transforms.transforms.Grayscale(3),\n",
        "          self.train_transform\n",
        "      ])\n",
        "          self.val_transform = transforms.Compose([\n",
        "          transforms.transforms.Grayscale(3),\n",
        "          self.val_transform\n",
        "      ])\n",
        "\n",
        "    # This function sets up our datasets\n",
        "    # which includes downloading and applying the augmentations\n",
        "    def prepare_data(self):\n",
        "      if self.fmnist:\n",
        "        self.train_set = FashionMNIST(root='./data', train=True,download=True, transform=self.train_transform)\n",
        "        self.val_set = FashionMNIST(root='./data', train=False,download=True, transform=self.val_transform)\n",
        "      else:\n",
        "        self.train_set = CIFAR10(root='./data', train=True,download=True, transform=self.train_transform)\n",
        "        self.val_set = CIFAR10(root='./data', train=False,download=True, transform=self.val_transform)\n",
        "\n",
        "    # This functions sets up the data loaders\n",
        "    def setup(self):\n",
        "        self.train_data_loader = torch.utils.data.DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
        "        self.val_data_loader = torch.utils.data.DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    # This is simply a getter function for the training data loader\n",
        "    def train_dataloader(self):\n",
        "        return self.train_data_loader\n",
        "\n",
        "    # This is simply a getter function for the validation data loader\n",
        "    def val_dataloader(self):\n",
        "        return self.val_data_loader"
      ],
      "metadata": {
        "id": "jVlClsSaAWLC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the Model Class\n",
        "Here we will define the model, its forward pass and its behaviour during each training/validation iteration"
      ],
      "metadata": {
        "id": "CZn5aEUYE09y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DLModel(torch.nn.Module):\n",
        "     def __init__(self, num_classes, pretrained=True, num_unfreeze_layers=0):\n",
        "        super().__init__()\n",
        "        # If you want to use the imagenet pretrained weights\n",
        "        if pretrained:\n",
        "            self.backbone = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "            # We freeze the entire model\n",
        "            self.backbone.requires_grad_(False)\n",
        "            # If you want to unfreeze some of the layers, then\n",
        "            if num_unfreeze_layers > 0:\n",
        "                # First find number of layers\n",
        "                num_layers = 0\n",
        "                for name, module in self.named_modules():\n",
        "                    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) or isinstance(module, torch.nn.BatchNorm2d):\n",
        "                        num_layers+=1\n",
        "                # Following which unfreeze the last set of layers\n",
        "                start_unfreezing_counter, counter = num_layers - num_unfreeze_layers, 0\n",
        "                for name, module in self.named_modules():\n",
        "                    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) or isinstance(module, torch.nn.BatchNorm2d):\n",
        "                        counter+=1\n",
        "                    if counter >= start_unfreezing_counter:\n",
        "                        module.requires_grad_(True)\n",
        "        # Otherwise just initialize the network from scratch\n",
        "        else:\n",
        "            self.backbone = resnet18(weights=None)\n",
        "            self.backbone.requires_grad_(True)\n",
        "        # The resnet model comes with a 1000 neuron final layer for the imagenet dataset\n",
        "        self.backbone.fc = torch.nn.Sequential(torch.nn.Linear(512, num_classes)\n",
        "        )\n",
        "        self.backbone.fc.requires_grad_(True)\n",
        "        # for name, module in self.named_modules():\n",
        "        #     print(name, all(param.requires_grad for param in module.parameters()))\n",
        "        # Define the objective function\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        # Define the metrics\n",
        "        self.train_acc1, self.val_acc1 = Accuracy(task=\"multiclass\", num_classes=num_classes), Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.train_acc5, self.val_acc5 = Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=5), Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=5)\n",
        "\n",
        "    # This function sets up the optimizer and scheduler that we will use\n",
        "     def configure_optimizers(self, lr, momentum, max_epochs):\n",
        "        self.optimizer = torch.optim.SGD(self.parameters(), lr=lr, momentum=momentum)\n",
        "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs)\n",
        "\n",
        "    # This defines the behaviour of our model during the forward pass\n",
        "    # Based on the defined behaviour, PyTorch sets up the backward pass\n",
        "     def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "        return out\n",
        "\n",
        "    # This function describes model behaviour per iteration during training\n",
        "     def training_step(self, x, y):\n",
        "        self.optimizer.zero_grad()\n",
        "        preds = self.forward(x)\n",
        "        self.train_acc1.update(preds, y)\n",
        "        self.train_acc5.update(preds, y)\n",
        "        loss = self.criterion(preds, y)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    # Once the epoch is complete, we can call this function for inspecting the model's performance\n",
        "     def on_training_epoch_end(self, loss, epoch):\n",
        "        acc1, acc5 = self.train_acc1.compute().item(), self.train_acc5.compute().item()\n",
        "        print(f\"Epoch No: {epoch+1}\\nTraining Loss: {loss}\\n Training Accuracy: {acc1} (Top-1)\\t  {acc5} (Top-5)\")\n",
        "        return acc1, acc5\n",
        "\n",
        "    # This function describes model behaviour per iteration during validation\n",
        "     def validation_step(self, x, y):\n",
        "        preds = self.forward(x)\n",
        "        self.val_acc1.update(preds, y)\n",
        "        self.val_acc5.update(preds, y)\n",
        "        loss = self.criterion(preds, y)\n",
        "        return loss.item()\n",
        "\n",
        "    # Once the validation iterations are complete, we can call this function for inspecting the model's performance\n",
        "     def on_validation_epoch_end(self, loss, epoch):\n",
        "        acc1, acc5 = self.val_acc1.compute().item(), self.val_acc5.compute().item()\n",
        "        print(f\"Validation Loss: {loss}\\nValidation Accuracy: {acc1} (Top-1)\\t  {acc5} (Top-5)\")\n",
        "        return acc1, acc5\n",
        "\n",
        "    # This function resets the metrics so that new results can be calculated for the next epoch\n",
        "     def reset_metrics(self):\n",
        "        self.train_acc1.reset(), self.train_acc5.reset()\n",
        "        self.val_acc1.reset(), self.val_acc5.reset()\n",
        ""
      ],
      "metadata": {
        "id": "hymXqMnjE7zo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together\n",
        "We first define some static and global variables"
      ],
      "metadata": {
        "id": "alJTaHprrWmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First define some static variables\n",
        "num_classes = 100\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "# Fine-tuning and training from scratch require different sets of learning rates\n",
        "lr_finetune, lr_scratch = 0.001, 0.1\n",
        "momentum = 0.9\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "hzedEOYLrhkE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shallow Fine-tuning\n",
        "We first take a look at shallow fine-tuning (training only the final layer and keeping the remaining model frozen)"
      ],
      "metadata": {
        "id": "ngfnnoLqrnKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR10 Dataset"
      ],
      "metadata": {
        "id": "6Wtb8Zp4rw9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data\n",
        "data_module = DataModule(batch_size=batch_size)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "train_loader, val_loader = data_module.train_dataloader(),data_module.val_dataloader()\n",
        "\n",
        "# This variable will be used to save the per-epoch validation accuracy\n",
        "shallow_finetuning_cifar10_val_acc = list()\n",
        "# This variable will be used to save the per-epoch training loss\n",
        "shallow_finetuning_cifar10_train_loss = list()\n",
        "\n",
        "# Define the model\n",
        "model = DLModel(num_classes=num_classes, pretrained=True,num_unfreeze_layers=0).to(device)\n",
        "model.configure_optimizers(lr=lr_finetune, momentum=momentum,max_epochs=num_epochs)\n",
        "\n",
        "# Start the training loop\n",
        "for epoch in range(num_epochs):\n",
        "  # This is the training cycle\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and update the model\n",
        "  for x, y in tqdm(train_loader, total=len(train_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.training_step(x, y)\n",
        "  avg_loss/=len(train_loader)\n",
        "  shallow_finetuning_cifar10_train_loss.append(avg_loss)\n",
        "  acc1, acc5 = model.on_training_epoch_end(avg_loss, epoch)\n",
        "\n",
        "  # This is the validation cycle\n",
        "  model.eval()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and get the predictions\n",
        "  for x, y in tqdm(val_loader, total=len(val_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.validation_step(x, y)\n",
        "  avg_loss/=len(val_loader)\n",
        "  acc1, acc5 = model.on_validation_epoch_end(avg_loss, epoch)\n",
        "  shallow_finetuning_cifar10_val_acc.append(acc1)\n",
        "  # Finally reset the metrics before going on to the next epoch\n",
        "  model.reset_metrics()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "MIKkZ4uUrtAN",
        "outputId": "7f1eb9ee-4bf6-45d1-ca18-024ffc970730"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 15694254.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 51.0MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-766e25742bff>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_unfreeze_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_finetune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1158\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                     )\n\u001b[0;32m-> 1160\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1161\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  FashionMNIST Dataset"
      ],
      "metadata": {
        "id": "hOzQTbMuA0kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data\n",
        "data_module = DataModule(batch_size=batch_size, fmnist=True)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "train_loader, val_loader = data_module.train_dataloader(),data_module.val_dataloader()\n",
        "# This variable will be used to save the per-epoch validation accuracy\n",
        "shallow_finetuning_mnist_val_acc = list()\n",
        "# This variable will be used to save the per-epoch training loss\n",
        "shallow_finetuning_mnist_train_loss = list()\n",
        "\n",
        "# Define the model\n",
        "model = DLModel(num_classes=num_classes, pretrained=True,num_unfreeze_layers=0).to(device)\n",
        "model.configure_optimizers(lr=lr_finetune, momentum=momentum,max_epochs=num_epochs)\n",
        "\n",
        "# Start the training loop\n",
        "for epoch in range(num_epochs):\n",
        "  # This is the training cycle\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and update the model\n",
        "  for x, y in tqdm(train_loader, total=len(train_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.training_step(x, y)\n",
        "  avg_loss/=len(train_loader)\n",
        "  shallow_finetuning_mnist_train_loss.append(avg_loss)\n",
        "  acc1, acc5 = model.on_training_epoch_end(avg_loss, epoch)\n",
        "\n",
        "  # This is the validation cycle\n",
        "  model.eval()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and get the predictions\n",
        "  for x, y in tqdm(val_loader, total=len(val_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.validation_step(x, y)\n",
        "  avg_loss/=len(val_loader)\n",
        "  acc1, acc5 = model.on_validation_epoch_end(avg_loss, epoch)\n",
        "  shallow_finetuning_mnist_val_acc.append(acc1)\n",
        "  # Finally reset the metrics before going on to the next epoch\n",
        "  model.reset_metrics()"
      ],
      "metadata": {
        "id": "gmC5hDZxA8bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Tunning\n",
        "We now take a look at deep fine-tuning (training some the final layers while keeping the remaining layers frozen)"
      ],
      "metadata": {
        "id": "kIPdTEf2GJgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR10 Dataset"
      ],
      "metadata": {
        "id": "dwuu_23cGerr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data\n",
        "data_module = DataModule(batch_size=batch_size)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "train_loader, val_loader = data_module.train_dataloader(),data_module.val_dataloader()\n",
        "\n",
        "# This variable will be used to save the per-epoch validation accuracy\n",
        "deep_finetuning_cifar10_val_acc = list()\n",
        "# This variable will be used to save the per-epoch training loss\n",
        "deep_finetuning_cifar10_train_loss = list()\n",
        "\n",
        "# Define the model\n",
        "model = DLModel(num_classes=num_classes, pretrained=True,num_unfreeze_layers=31).to(device)\n",
        "model.configure_optimizers(lr=lr_finetune, momentum=momentum,max_epochs=num_epochs)\n",
        "\n",
        "# Start the training loop\n",
        "for epoch in range(num_epochs):\n",
        "  # This is the training cycle\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and update the model\n",
        "  for x, y in tqdm(train_loader, total=len(train_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.training_step(x, y)\n",
        "  avg_loss/=len(train_loader)\n",
        "  deep_finetuning_cifar10_train_loss.append(avg_loss)\n",
        "  acc1, acc5 = model.on_training_epoch_end(avg_loss, epoch)\n",
        "\n",
        "  # This is the validation cycle\n",
        "  model.eval()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and get the predictions\n",
        "  for x, y in tqdm(val_loader, total=len(val_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.validation_step(x, y)\n",
        "  avg_loss/=len(val_loader)\n",
        "  acc1, acc5 = model.on_validation_epoch_end(avg_loss, epoch)\n",
        "  deep_finetuning_cifar10_val_acc.append(acc1)\n",
        "  # Finally reset the metrics before going on to the next epoch\n",
        "  model.reset_metrics()\n"
      ],
      "metadata": {
        "id": "68eYnQmEGlkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FashionMNIST Dataset"
      ],
      "metadata": {
        "id": "53Z4B3EDG9qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data\n",
        "data_module = DataModule(batch_size=batch_size, fmnist=True)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "train_loader, val_loader = data_module.train_dataloader(),data_module.val_dataloader()\n",
        "# This variable will be used to save the per-epoch validation accuracy\n",
        "deep_finetuning_mnist_val_acc = list()\n",
        "# This variable will be used to save the per-epoch training loss\n",
        "deep_finetuning_mnist_train_loss = list()\n",
        "\n",
        "# Define the model\n",
        "model = DLModel(num_classes=num_classes, pretrained=True,num_unfreeze_layers=31).to(device)\n",
        "model.configure_optimizers(lr=lr_finetune, momentum=momentum,max_epochs=num_epochs)\n",
        "\n",
        "# Start the training loop\n",
        "for epoch in range(num_epochs):\n",
        "  # This is the training cycle\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and update the model\n",
        "  for x, y in tqdm(train_loader, total=len(train_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.training_step(x, y)\n",
        "  avg_loss/=len(train_loader)\n",
        "  deep_finetuning_mnist_train_loss.append(avg_loss)\n",
        "  acc1, acc5 = model.on_training_epoch_end(avg_loss, epoch)\n",
        "\n",
        "  # This is the validation cycle\n",
        "  model.eval()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and get the predictions\n",
        "  for x, y in tqdm(val_loader, total=len(val_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.validation_step(x, y)\n",
        "  avg_loss/=len(val_loader)\n",
        "  acc1, acc5 = model.on_validation_epoch_end(avg_loss, epoch)\n",
        "  deep_finetuning_mnist_val_acc.append(acc1)\n",
        "  # Finally reset the metrics before going on to the next epoch\n",
        "  model.reset_metrics()"
      ],
      "metadata": {
        "id": "Dk7TMSj-HCJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training from Scratch\n",
        "Finally, we train the ResNet18 model from scratch."
      ],
      "metadata": {
        "id": "e-Wvg39MHm1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR10 Dataset"
      ],
      "metadata": {
        "id": "GXjEqI9DH0mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data\n",
        "data_module = DataModule(batch_size=batch_size)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "train_loader, val_loader = data_module.train_dataloader(),data_module.val_dataloader()\n",
        "\n",
        "# This variable will be used to save the per-epoch validation accuracy\n",
        "scratch_cifar10_val_acc = list()\n",
        "# This variable will be used to save the per-epoch training loss\n",
        "scratch_cifar10_train_loss = list()\n",
        "\n",
        "# Define the model\n",
        "model = DLModel(num_classes=num_classes, pretrained=False,num_unfreeze_layers=31).to(device)\n",
        "model.configure_optimizers(lr=lr_finetune, momentum=momentum,max_epochs=num_epochs)\n",
        "\n",
        "# Start the training loop\n",
        "for epoch in range(num_epochs):\n",
        "  # This is the training cycle\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and update the model\n",
        "  for x, y in tqdm(train_loader, total=len(train_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.training_step(x, y)\n",
        "  avg_loss/=len(train_loader)\n",
        "  scratch_cifar10_train_loss.append(avg_loss)\n",
        "  acc1, acc5 = model.on_training_epoch_end(avg_loss, epoch)\n",
        "\n",
        "  # This is the validation cycle\n",
        "  model.eval()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and get the predictions\n",
        "  for x, y in tqdm(val_loader, total=len(val_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.validation_step(x, y)\n",
        "  avg_loss/=len(val_loader)\n",
        "  acc1, acc5 = model.on_validation_epoch_end(avg_loss, epoch)\n",
        "  scratch_cifar10_val_acc.append(acc1)\n",
        "  # Finally reset the metrics before going on to the next epoch\n",
        "  model.reset_metrics()\n"
      ],
      "metadata": {
        "id": "gTvn6B6iH7fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FashionMNIST Dataset"
      ],
      "metadata": {
        "id": "dumDBJ-PIUIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data\n",
        "data_module = DataModule(batch_size=batch_size, fmnist=True)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "train_loader, val_loader = data_module.train_dataloader(),data_module.val_dataloader()\n",
        "# This variable will be used to save the per-epoch validation accuracy\n",
        "scratch_mnist_val_acc = list()\n",
        "# This variable will be used to save the per-epoch training loss\n",
        "scratch_mnist_train_loss = list()\n",
        "\n",
        "# Define the model\n",
        "model = DLModel(num_classes=num_classes, pretrained=False,num_unfreeze_layers=31).to(device)\n",
        "model.configure_optimizers(lr=lr_finetune, momentum=momentum,max_epochs=num_epochs)\n",
        "\n",
        "# Start the training loop\n",
        "for epoch in range(num_epochs):\n",
        "  # This is the training cycle\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and update the model\n",
        "  for x, y in tqdm(train_loader, total=len(train_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.training_step(x, y)\n",
        "  avg_loss/=len(train_loader)\n",
        "  scratch_mnist_train_loss.append(avg_loss)\n",
        "  acc1, acc5 = model.on_training_epoch_end(avg_loss, epoch)\n",
        "\n",
        "  # This is the validation cycle\n",
        "  model.eval()\n",
        "  avg_loss = 0\n",
        "  # Iterate over each batch and get the predictions\n",
        "  for x, y in tqdm(val_loader, total=len(val_loader)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    avg_loss+= model.validation_step(x, y)\n",
        "  avg_loss/=len(val_loader)\n",
        "  acc1, acc5 = model.on_validation_epoch_end(avg_loss, epoch)\n",
        "  scratch_mnist_val_acc.append(acc1)\n",
        "  # Finally reset the metrics before going on to the next epoch\n",
        "  model.reset_metrics()"
      ],
      "metadata": {
        "id": "xSuYsORzIYPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparisons\n",
        "Now that we have evaluated the models under three different forms of training, let us compare them."
      ],
      "metadata": {
        "id": "juIwwJl3JCKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR10 Dataset"
      ],
      "metadata": {
        "id": "RihGpxBRJIdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the Training loss per epoch\n",
        "sns.lineplot(x=np.arange(len(shallow_finetuning_cifar10_train_loss)), y=shallow_finetuning_cifar10_train_loss, label=\"Shallow Fine-tuning\")\n",
        "sns.lineplot(x=np.arange(len(deep_finetuning_cifar10_train_loss)), y=deep_finetuning_cifar10_train_loss, label=\"Deep Fine-tuning\")\n",
        "sns.lineplot(x=np.arange(len(scratch_cifar10_train_loss)), y=scratch_cifar10_train_loss, label=\"Training from scratch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "sns.despine()\n",
        "plt.title(\"Training Loss Comparison\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# Comparing the validation Accuracies per epoch\n",
        "sns.lineplot(x=np.arange(len(shallow_finetuning_cifar10_val_acc)), y=shallow_finetuning_cifar10_val_acc, label=\"Shallow Fine-tuning\")\n",
        "sns.lineplot(x=np.arange(len(deep_finetuning_cifar10_val_acc)), y=deep_finetuning_cifar10_val_acc, label=\"Deep Fine-tuning\")\n",
        "sns.lineplot(x=np.arange(len(scratch_cifar10_val_acc)), y=scratch_cifar10_val_acc, label=\"Training from scratch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "sns.despine()\n",
        "plt.title(\"Validation Accuracy Comparison\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iWYVVN6HJOki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FashionMNIST Dataset"
      ],
      "metadata": {
        "id": "U8K1BEQ6KEDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the Training loss per epoch\n",
        "sns.lineplot(x=np.arange(len(shallow_finetuning_mnist_train_loss)), y=shallow_finetuning_mnist_train_loss, label=\"Shallow Fine-tuning\")\n",
        "sns.lineplot(x=np.arange(len(deep_finetuning_mnist_train_loss)), y=deep_finetuning_mnist_train_loss, label=\"Deep Fine-tuning\")\n",
        "sns.lineplot(x=np.arange(len(scratch_mnist_train_loss)), y=scratch_mnist_train_loss, label=\"Training from scratch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "sns.despine()\n",
        "plt.title(\"Training Loss Comparison\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# Comparing the validation Accuracies per epoch\n",
        "sns.lineplot(x=np.arange(len(shallow_finetuning_mnist_val_acc)), y=shallow_finetuning_mnist_val_acc, label=\"Shallow Fine-tuning\")\n",
        "sns.lineplot(x=np.arange(len(deep_finetuning_mnist_val_acc)), y=deep_finetuning_mnist_val_acc, label=\"Deep Fine-tuning\")\n",
        "sns.lineplot(x=np.arange(len(scratch_mnist_val_acc)), y=scratch_mnist_val_acc, label=\"Training from scratch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "sns.despine()\n",
        "plt.title(\"Validation Accuracy Comparison\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oQ6xaLkVKF4E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}